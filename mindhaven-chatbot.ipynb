{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12167732,"sourceType":"datasetVersion","datasetId":7663566}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## INTRODUCTION\nMindHaven_ChatBot is a domain-specific mental health chatbot designed to simulate counseling conversations using the T5 Transformer model. It helps users navigate emotional difficulties by generating empathetic, informed responses based on a curated dataset from Hugging Face.","metadata":{"id":"Gmqk8QyiL0yM"}},{"cell_type":"code","source":"# Installing dependencies\n!pip install --upgrade transformers datasets sentencepiece\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWea-Bx0M3CT","outputId":"7b42d9ca-4bd5-4906-8c7b-f24fabeef507","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T22:54:18.504691Z","iopub.execute_input":"2025-06-18T22:54:18.505440Z","iopub.status.idle":"2025-06-18T22:54:21.936329Z","shell.execute_reply.started":"2025-06-18T22:54:18.505416Z","shell.execute_reply":"2025-06-18T22:54:21.935584Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Importing libraries\nimport pandas as pd\nimport json\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\nfrom transformers import (\n    T5Tokenizer,\n    TFT5ForConditionalGeneration,\n    DataCollatorForSeq2Seq,\n    create_optimizer\n)\nimport tensorflow as tf\n","metadata":{"id":"iC_g_-7xNb5g","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T22:54:26.211322Z","iopub.execute_input":"2025-06-18T22:54:26.212035Z","iopub.status.idle":"2025-06-18T22:54:26.216139Z","shell.execute_reply.started":"2025-06-18T22:54:26.212006Z","shell.execute_reply":"2025-06-18T22:54:26.215602Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Loading the dataset from Kaggle (updated path)\nwith open(\"/kaggle/input/mindhaven-dataset-json/mindhaven_dataset.json\", \"r\") as f:\n    data = [json.loads(line) for line in f]\n\n# Converting to DataFrame\ndf = pd.DataFrame(data)\n\n# Displaying shape and preview\nprint(f\"Total samples: {len(df)}\")\ndf.head()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"P3jP8IoyFUF1","outputId":"102f6d11-6663-4142-8e32-8c35b6770295","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T22:54:30.321256Z","iopub.execute_input":"2025-06-18T22:54:30.321890Z","iopub.status.idle":"2025-06-18T22:54:30.384321Z","shell.execute_reply.started":"2025-06-18T22:54:30.321866Z","shell.execute_reply":"2025-06-18T22:54:30.383666Z"}},"outputs":[{"name":"stdout","text":"Total samples: 3512\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                             Context  \\\n0  I'm going through some things with my feelings...   \n1  I'm going through some things with my feelings...   \n2  I'm going through some things with my feelings...   \n3  I'm going through some things with my feelings...   \n4  I'm going through some things with my feelings...   \n\n                                            Response  \n0  If everyone thinks you're worthless, then mayb...  \n1  Hello, and thank you for your question and see...  \n2  First thing I'd suggest is getting the sleep y...  \n3  Therapy is essential for those that are feelin...  \n4  I first want to let you know that you are not ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Context</th>\n      <th>Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I'm going through some things with my feelings...</td>\n      <td>If everyone thinks you're worthless, then mayb...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I'm going through some things with my feelings...</td>\n      <td>Hello, and thank you for your question and see...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I'm going through some things with my feelings...</td>\n      <td>First thing I'd suggest is getting the sleep y...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I'm going through some things with my feelings...</td>\n      <td>Therapy is essential for those that are feelin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I'm going through some things with my feelings...</td>\n      <td>I first want to let you know that you are not ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"## Cleaning & preparing the dataset","metadata":{"id":"0WD4gD0vT93M"}},{"cell_type":"code","source":"# Renaming columns\ndf.rename(columns={\"Context\": \"input_text\", \"Response\": \"target_text\"}, inplace=True)\n\n# Dropping NaNs and cleaning text\ndf.dropna(subset=[\"input_text\", \"target_text\"], inplace=True)\ndf[\"input_text\"] = df[\"input_text\"].astype(str).str.strip().str.lower()\ndf[\"target_text\"] = df[\"target_text\"].astype(str).str.strip()\ndf = df[(df[\"input_text\"] != \"\") & (df[\"target_text\"] != \"\")]","metadata":{"id":"VmnkCVUcT81Z","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T22:54:33.901330Z","iopub.execute_input":"2025-06-18T22:54:33.902034Z","iopub.status.idle":"2025-06-18T22:54:33.922292Z","shell.execute_reply.started":"2025-06-18T22:54:33.902009Z","shell.execute_reply":"2025-06-18T22:54:33.921661Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Splitting into train/val and saving\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\ntrain_df.to_csv(\"mindhaven_train.csv\", index=False)\nval_df.to_csv(\"mindhaven_val.csv\", index=False)","metadata":{"id":"Y5tDPZ63T8w_","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T22:54:37.151308Z","iopub.execute_input":"2025-06-18T22:54:37.151966Z","iopub.status.idle":"2025-06-18T22:54:37.306864Z","shell.execute_reply.started":"2025-06-18T22:54:37.151946Z","shell.execute_reply":"2025-06-18T22:54:37.306245Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Loading the tokenizer\ntokenizer = T5Tokenizer.from_pretrained(\"t5-small\")","metadata":{"id":"8JWu0N0GT8ud","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T22:54:39.241628Z","iopub.execute_input":"2025-06-18T22:54:39.241896Z","iopub.status.idle":"2025-06-18T22:54:39.839955Z","shell.execute_reply.started":"2025-06-18T22:54:39.241879Z","shell.execute_reply":"2025-06-18T22:54:39.839349Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Defining tokenization function\ndef tokenize_data(input_texts, target_texts, tokenizer, max_input_length=128, max_target_length=128):\n    input_encodings = tokenizer(\n        input_texts,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=max_input_length,\n        return_tensors=\"np\"\n    )\n    target_encodings = tokenizer(\n        target_texts,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=max_target_length,\n        return_tensors=\"np\"\n    )\n    return input_encodings, target_encodings\n","metadata":{"id":"CbVcZcL5T8sM","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T22:54:44.985281Z","iopub.execute_input":"2025-06-18T22:54:44.985556Z","iopub.status.idle":"2025-06-18T22:54:44.990235Z","shell.execute_reply.started":"2025-06-18T22:54:44.985535Z","shell.execute_reply":"2025-06-18T22:54:44.989409Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Tokenizing the clean CSVs\ntrain_df = pd.read_csv(\"mindhaven_train.csv\")\nval_df = pd.read_csv(\"mindhaven_val.csv\")\n\ntrain_inputs, train_targets = tokenize_data(\n    train_df[\"input_text\"].tolist(),\n    train_df[\"target_text\"].tolist(),\n    tokenizer\n)\n\nval_inputs, val_targets = tokenize_data(\n    val_df[\"input_text\"].tolist(),\n    val_df[\"target_text\"].tolist(),\n    tokenizer\n)","metadata":{"id":"Nty0M-luT8p2","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T22:54:49.217240Z","iopub.execute_input":"2025-06-18T22:54:49.217509Z","iopub.status.idle":"2025-06-18T22:54:53.081522Z","shell.execute_reply.started":"2025-06-18T22:54:49.217490Z","shell.execute_reply":"2025-06-18T22:54:53.080690Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Converting to tf.data.Dataset\ntrain_dataset = tf.data.Dataset.from_tensor_slices({\n    \"input_ids\": train_inputs[\"input_ids\"],\n    \"attention_mask\": train_inputs[\"attention_mask\"],\n    \"labels\": train_targets[\"input_ids\"]\n}).shuffle(1000).batch(8).prefetch(tf.data.AUTOTUNE)\n\nval_dataset = tf.data.Dataset.from_tensor_slices({\n    \"input_ids\": val_inputs[\"input_ids\"],\n    \"attention_mask\": val_inputs[\"attention_mask\"],\n    \"labels\": val_targets[\"input_ids\"]\n}).batch(8).prefetch(tf.data.AUTOTUNE)\n","metadata":{"id":"R1jMo4GoT8nc","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T22:54:56.809417Z","iopub.execute_input":"2025-06-18T22:54:56.809685Z","iopub.status.idle":"2025-06-18T22:54:56.844134Z","shell.execute_reply.started":"2025-06-18T22:54:56.809668Z","shell.execute_reply":"2025-06-18T22:54:56.843465Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# Loading the t5-small model\nmodel = TFT5ForConditionalGeneration.from_pretrained(\"t5-small\")\n\n# Defining the number of training steps \nEPOCHS = 40\nBATCH_SIZE = 8\nnum_train_steps = len(train_dataset) * EPOCHS\n\n# Optimizer with hyperparameters\noptimizer, schedule = create_optimizer(\n    init_lr=0.001,             \n    num_warmup_steps=200,      \n    num_train_steps=num_train_steps\n)\n\n# Custom training wrapper\nclass T5ModelWrapper(tf.keras.Model):\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n\n    def train_step(self, data):\n        x = data\n        with tf.GradientTape() as tape:\n            outputs = self.model(**x, training=True)\n            loss = outputs.loss\n        gradients = tape.gradient(loss, self.model.trainable_variables)\n        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n        return {\"loss\": loss}\n\n    def test_step(self, data):\n        x = data\n        outputs = self.model(**x, training=False)\n        return {\"loss\": outputs.loss}\n\n# Compiling and training\nwrapped_model = T5ModelWrapper(model)\nwrapped_model.compile(optimizer=optimizer)\n\nwrapped_model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=EPOCHS\n)\n\n# Saving the model & tokenizer\nmodel.save_pretrained(\"./mindhaven_t5_model_tf\")\ntokenizer.save_pretrained(\"./mindhaven_t5_model_tf\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wh5Dri_LT8lH","outputId":"1d75c879-e073-4279-ff80-ba1b40bbfb18","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T22:55:48.450277Z","iopub.execute_input":"2025-06-18T22:55:48.451003Z","iopub.status.idle":"2025-06-18T23:30:02.754423Z","shell.execute_reply.started":"2025-06-18T22:55:48.450980Z","shell.execute_reply":"2025-06-18T23:30:02.753780Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22622941563c490d9dbc5dc7050c54a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b714ba85133040d2904773912436a632"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n\nAll the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1750287386.866950     102 service.cc:148] XLA service 0x7fde9d6788c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1750287386.867877     102 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1750287386.979435     102 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1750287387.139975     102 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"395/395 [==============================] - 98s 139ms/step - loss: 3.5759 - val_loss: 3.2875\nEpoch 2/40\n395/395 [==============================] - 50s 126ms/step - loss: 3.0628 - val_loss: 3.1055\nEpoch 3/40\n395/395 [==============================] - 50s 126ms/step - loss: 2.8604 - val_loss: 2.9787\nEpoch 4/40\n395/395 [==============================] - 50s 126ms/step - loss: 2.6908 - val_loss: 2.8890\nEpoch 5/40\n395/395 [==============================] - 50s 126ms/step - loss: 2.5328 - val_loss: 2.7939\nEpoch 6/40\n395/395 [==============================] - 50s 126ms/step - loss: 2.3909 - val_loss: 2.7108\nEpoch 7/40\n395/395 [==============================] - 50s 126ms/step - loss: 2.2575 - val_loss: 2.6458\nEpoch 8/40\n395/395 [==============================] - 50s 126ms/step - loss: 2.1235 - val_loss: 2.5823\nEpoch 9/40\n395/395 [==============================] - 50s 126ms/step - loss: 2.0074 - val_loss: 2.5054\nEpoch 10/40\n395/395 [==============================] - 50s 126ms/step - loss: 1.8909 - val_loss: 2.4856\nEpoch 11/40\n395/395 [==============================] - 50s 126ms/step - loss: 1.7858 - val_loss: 2.4647\nEpoch 12/40\n395/395 [==============================] - 50s 126ms/step - loss: 1.6878 - val_loss: 2.3577\nEpoch 13/40\n395/395 [==============================] - 50s 127ms/step - loss: 1.5916 - val_loss: 2.3094\nEpoch 14/40\n395/395 [==============================] - 50s 127ms/step - loss: 1.5116 - val_loss: 2.3284\nEpoch 15/40\n395/395 [==============================] - 50s 127ms/step - loss: 1.4304 - val_loss: 2.3298\nEpoch 16/40\n395/395 [==============================] - 50s 127ms/step - loss: 1.3530 - val_loss: 2.2719\nEpoch 17/40\n395/395 [==============================] - 50s 127ms/step - loss: 1.2886 - val_loss: 2.2838\nEpoch 18/40\n395/395 [==============================] - 50s 127ms/step - loss: 1.2200 - val_loss: 2.2596\nEpoch 19/40\n395/395 [==============================] - 50s 128ms/step - loss: 1.1637 - val_loss: 2.2393\nEpoch 20/40\n395/395 [==============================] - 50s 127ms/step - loss: 1.1059 - val_loss: 2.2243\nEpoch 21/40\n395/395 [==============================] - 50s 127ms/step - loss: 1.0573 - val_loss: 2.2473\nEpoch 22/40\n395/395 [==============================] - 50s 127ms/step - loss: 1.0065 - val_loss: 2.2296\nEpoch 23/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.9677 - val_loss: 2.1486\nEpoch 24/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.9229 - val_loss: 2.1408\nEpoch 25/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.8904 - val_loss: 2.1458\nEpoch 26/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.8504 - val_loss: 2.1329\nEpoch 27/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.8201 - val_loss: 2.1639\nEpoch 28/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.7894 - val_loss: 2.2008\nEpoch 29/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.7660 - val_loss: 2.2161\nEpoch 30/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.7365 - val_loss: 2.2416\nEpoch 31/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.7159 - val_loss: 2.1832\nEpoch 32/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.6926 - val_loss: 2.2116\nEpoch 33/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.6762 - val_loss: 2.2234\nEpoch 34/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.6563 - val_loss: 2.2179\nEpoch 35/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.6407 - val_loss: 2.2224\nEpoch 36/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.6234 - val_loss: 2.2109\nEpoch 37/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.6131 - val_loss: 2.2305\nEpoch 38/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.6043 - val_loss: 2.2231\nEpoch 39/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.5946 - val_loss: 2.2220\nEpoch 40/40\n395/395 [==============================] - 50s 127ms/step - loss: 0.5906 - val_loss: 2.2318\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"('./mindhaven_t5_model_tf/tokenizer_config.json',\n './mindhaven_t5_model_tf/special_tokens_map.json',\n './mindhaven_t5_model_tf/spiece.model',\n './mindhaven_t5_model_tf/added_tokens.json')"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"# Loading the model and tokenizer\nfrom transformers import TFT5ForConditionalGeneration, T5Tokenizer\n\nmodel = TFT5ForConditionalGeneration.from_pretrained(\"./mindhaven_t5_model_tf\")\ntokenizer = T5Tokenizer.from_pretrained(\"./mindhaven_t5_model_tf\")\n\n# Defining the chatbot response function\ndef ask_bot(question):\n    prompt = f\"Mental health support: {question.strip()}\"\n\n    inputs = tokenizer(\n        prompt,\n        return_tensors=\"tf\",\n        padding=\"max_length\",\n        truncation=True,\n        max_length=128\n    )\n\n    outputs = model.generate(\n        input_ids=inputs.input_ids,\n        attention_mask=inputs.attention_mask,\n        max_length=100,\n        min_length=30,\n        no_repeat_ngram_size=3,\n        repetition_penalty=1.8,\n        num_beams=5,\n        early_stopping=True\n    )\n\n    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n\n# testing the bot\nprint(\"Bot:\", ask_bot(\"I feel anxious and can't sleep at night.what should i do?\"))\nprint(\"Bot:\", ask_bot(\"I’m always overthinking and feel drained.\"))\nprint(\"Bot:\", ask_bot(\"Lately, I’ve been feeling like I’m not good enough.\"))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOLGaC7e7tsV","outputId":"9f341094-cc6b-4360-b2d0-5ae08ae8e2a1","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T23:31:46.138989Z","iopub.execute_input":"2025-06-18T23:31:46.139670Z","iopub.status.idle":"2025-06-18T23:32:55.512904Z","shell.execute_reply.started":"2025-06-18T23:31:46.139647Z","shell.execute_reply":"2025-06-18T23:32:55.512087Z"}},"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n\nAll the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at ./mindhaven_t5_model_tf.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Bot: Mental health support: You feel anxious and can't sleep at night. What should I do? First off, I would recommend a book called \"The Five Agreements\" about Mental Health Support. You can read about it here: http://www.psychologytoday.com/what-makes-a-service-for-you-will-bear.htm. Another suggestion is to write a letter to your health care provider about your anxiety and sleep\nBot: Mental Health Support: You are always overthinking and feeling drained. I always suggest that you see a mental health support provider if you have one. There are several reasons why you might feel this way.First, you should check out my website on Psychology Today, which is a blog from the National Institutes of Health. You can search for a support group in your zip code and search more specifically for the National Child Abuse Hotline.\nBot: Mental health support: You're in a place of constant flux and change. I don't know how old you are, but if you are an adult, you might want to have a conversation with your doctor or a counselor about getting you started and looking for someone to talk to. If you feel like you are a good match, maybe you should consider attending Couples therapy. They may be able to help you explore where you are coming from and what you\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"!zip -r mindhaven_t5_model_tf.zip mindhaven_t5_model_tf\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T23:33:29.551079Z","iopub.execute_input":"2025-06-18T23:33:29.551631Z","iopub.status.idle":"2025-06-18T23:33:48.974296Z","shell.execute_reply.started":"2025-06-18T23:33:29.551606Z","shell.execute_reply":"2025-06-18T23:33:48.973565Z"}},"outputs":[{"name":"stdout","text":"  adding: mindhaven_t5_model_tf/ (stored 0%)\n  adding: mindhaven_t5_model_tf/config.json (deflated 63%)\n  adding: mindhaven_t5_model_tf/spiece.model (deflated 48%)\n  adding: mindhaven_t5_model_tf/added_tokens.json (deflated 83%)\n  adding: mindhaven_t5_model_tf/generation_config.json (deflated 29%)\n  adding: mindhaven_t5_model_tf/tf_model.h5 (deflated 7%)\n  adding: mindhaven_t5_model_tf/tokenizer_config.json (deflated 94%)\n  adding: mindhaven_t5_model_tf/special_tokens_map.json (deflated 85%)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import shutil\nshutil.move(\"mindhaven_t5_model_tf.zip\", \"/kaggle/working/mindhaven_t5_model_tf.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T23:33:53.697295Z","iopub.execute_input":"2025-06-18T23:33:53.697573Z","iopub.status.idle":"2025-06-18T23:33:53.702673Z","shell.execute_reply.started":"2025-06-18T23:33:53.697552Z","shell.execute_reply":"2025-06-18T23:33:53.701967Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/mindhaven_t5_model_tf.zip'"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"!pip install -q transformers datasets evaluate sentencepiece\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T23:33:57.570336Z","iopub.execute_input":"2025-06-18T23:33:57.570843Z","iopub.status.idle":"2025-06-18T23:34:01.025674Z","shell.execute_reply.started":"2025-06-18T23:33:57.570821Z","shell.execute_reply":"2025-06-18T23:34:01.024901Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Reloading the trained model & tokenizer \nfrom transformers import TFT5ForConditionalGeneration, T5Tokenizer\nimport tensorflow as tf\n\nmodel = TFT5ForConditionalGeneration.from_pretrained(\"./mindhaven_t5_model_tf\")\ntokenizer = T5Tokenizer.from_pretrained(\"./mindhaven_t5_model_tf\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T23:34:05.818619Z","iopub.execute_input":"2025-06-18T23:34:05.819483Z","iopub.status.idle":"2025-06-18T23:34:07.161489Z","shell.execute_reply.started":"2025-06-18T23:34:05.819428Z","shell.execute_reply":"2025-06-18T23:34:07.160931Z"}},"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n\nAll the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at ./mindhaven_t5_model_tf.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# Defining the response function\n\ndef ask_bot(question):\n    prompt = f\"Mental health support: {question.strip()}\"\n    inputs = tokenizer(prompt, return_tensors=\"tf\", padding=\"max_length\", truncation=True, max_length=128)\n    output = model.generate(\n        input_ids=inputs.input_ids,\n        attention_mask=inputs.attention_mask,\n        max_length=80,\n        num_beams=3,\n        early_stopping=True\n    )\n    return tokenizer.decode(output[0], skip_special_tokens=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T23:34:19.036597Z","iopub.execute_input":"2025-06-18T23:34:19.037208Z","iopub.status.idle":"2025-06-18T23:34:19.041239Z","shell.execute_reply.started":"2025-06-18T23:34:19.037184Z","shell.execute_reply":"2025-06-18T23:34:19.040615Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Performance metrics (BLEU & F1)\nimport evaluate\n\n# BLEU\nbleu = evaluate.load(\"bleu\")\n\n# Sample inputs\nprompts = [\n    \"I feel anxious and can't sleep at night.\",\n    \"I'm feeling lost and alone.\",\n    \"I'm overwhelmed with work and life.\"\n]\n\n# References\nreferences = [\n    \"Try relaxation exercises or talk to someone you trust.\",\n    \"You're not alone—reach out to a mental health professional.\",\n    \"Take a break, breathe, and try to focus on one step at a time.\"\n]\n\n# Generating predictions\npredictions = [ask_bot(q) for q in prompts]\n\n# Computing BLEU\nbleu_result = bleu.compute(predictions=predictions, references=[[r] for r in references])\n\n# F1\ndef compute_token_f1(preds, refs):\n    total_f1 = 0.0\n    for pred, ref in zip(preds, refs):\n        pred_tokens = set(pred.lower().split())\n        ref_tokens = set(ref.lower().split())\n        common = pred_tokens & ref_tokens\n        if not common:\n            continue\n        precision = len(common) / len(pred_tokens)\n        recall = len(common) / len(ref_tokens)\n        f1 = 2 * precision * recall / (precision + recall)\n        total_f1 += f1\n    return total_f1 / len(preds)\n\nf1_score = compute_token_f1(predictions, references)\n\n# results\nimport pandas as pd\npd.DataFrame({\n    \"Metric\": [\"BLEU\", \"Token-level F1\"],\n    \"Score\": [round(bleu_result[\"bleu\"], 4), round(f1_score, 4)]\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T23:34:22.484038Z","iopub.execute_input":"2025-06-18T23:34:22.484340Z","iopub.status.idle":"2025-06-18T23:35:03.832296Z","shell.execute_reply.started":"2025-06-18T23:34:22.484321Z","shell.execute_reply":"2025-06-18T23:35:03.831573Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f072ed054d54f72aa631d1c6e372a1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35b63deedbda42c6a9dca3f73c0ea2b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68b8bc79878943d48ecc52354c16506b"}},"metadata":{}},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"           Metric   Score\n0            BLEU  0.0000\n1  Token-level F1  0.1276","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BLEU</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Token-level F1</td>\n      <td>0.1276</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":42},{"cell_type":"markdown","source":"# Summary\n\nI fine-tuned a T5-small transformer model on domain specific mental health Q&A dataset using TensorFlow and Hugging Face.\n\nHere below are some more\n\n\n**Details:**\n- Model: T5-small\n- Epochs: 40\n- Learning Rate: 0.001\n- Warmup Steps: 200\n- Batch Size: 8\n- Max Token Length: 128\n\n**Performance Metrics:**\n- BLEU Score: **0.0**\n- Token-level F1 Score: **0.1276**\n\n**Insights:**\n- Although the BLEU score is low, this is expected for generative tasks, the F1 score shows moderate token overlap with references.\n- The model generates coherent, domain-relevant, supportive mental health advice.\n- Limitations include: small dataset, open-ended nature of responses, and generic expression patterns.\n","metadata":{}}]}